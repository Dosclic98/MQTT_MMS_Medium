{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pgmpy.models\n",
    "import pgmpy.inference\n",
    "import numpy as np\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSlices = 24\n",
    "\n",
    "class NodeNames(Enum):\n",
    "    MITM = \"MITM\"\n",
    "    SRM = \"SRM\"\n",
    "    UC = \"UC\"\n",
    "    UPS = \"UPS\"\n",
    "    IMD = \"IMD\"\n",
    "    MC = \"MC\"\n",
    "    CC = \"CC\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySmile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysmile\n",
    "import pysmile_license\n",
    "import os\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "evidenceNodes = [NodeNames.IMD.value, NodeNames.MC.value, NodeNames.CC.value]\n",
    "\n",
    "classNodesHandles = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_node_info(net, node_handle):\n",
    "    print(\"Node id/name: \" + net.get_node_id(node_handle) + \"/\" +\n",
    "    net.get_node_name(node_handle))\n",
    "    print(\" Outcomes: \" + \" \".join(net.get_outcome_ids(node_handle)))\n",
    "    parent_ids = net.get_parent_ids(node_handle)\n",
    "    if len(parent_ids) > 0:\n",
    "        print(\" Parents: \" + \" \".join(parent_ids))\n",
    "    child_ids = net.get_child_ids(node_handle)\n",
    "    if len(child_ids) > 0:\n",
    "        print(\" Children: \" + \" \".join(child_ids))\n",
    "    print_cpt_matrix(net, node_handle)\n",
    "    \n",
    "def print_cpt_matrix(net, node_handle):\n",
    "    cpt = net.get_node_definition(node_handle)\n",
    "    parents = net.get_parents(node_handle)\n",
    "    dim_count = 1 + len(parents)\n",
    "    dim_sizes = [0] * dim_count\n",
    "    for i in range(0, dim_count - 1):\n",
    "        dim_sizes[i] = net.get_outcome_count(parents[i])\n",
    "    dim_sizes[len(dim_sizes) - 1] = net.get_outcome_count(node_handle)\n",
    "    coords = [0] * dim_count\n",
    "    for elem_idx in range(0, len(cpt)):\n",
    "        index_to_coords(elem_idx, dim_sizes, coords)\n",
    "        outcome = net.get_outcome_id(node_handle, coords[dim_count - 1])\n",
    "        out_str = \" P(\" + outcome\n",
    "        if dim_count > 1:\n",
    "            out_str += \" | \"\n",
    "            for parent_idx in range(0, len(parents)):\n",
    "                if parent_idx > 0:\n",
    "                    out_str += \",\"\n",
    "                parent_handle = parents[parent_idx]\n",
    "                out_str += net.get_node_id(parent_handle) + \"=\" + \\\n",
    "                net.get_outcome_id(parent_handle, coords[parent_idx])\n",
    "        prob = cpt[elem_idx]\n",
    "        out_str += \")=\" + str(prob)\n",
    "        print(out_str)\n",
    "    \n",
    "        \n",
    "def index_to_coords(index, dim_sizes, coords):\n",
    "    prod = 1\n",
    "    for i in range(len(dim_sizes) - 1, -1, -1):\n",
    "        coords[i] = int(index / prod) % dim_sizes[i]\n",
    "        prod *= dim_sizes[i]\n",
    "\n",
    "def pint_time_cpt_marix(net, nodeHandle):\n",
    "    timeCPT = net.get_node_temporal_definition(nodeHandle, 1)\n",
    "    \n",
    "        \n",
    "def plot_time_CPT(net, nodeHandle):    \n",
    "    cpt = net.get_node_temporal_definition(nodeHandle, 1)\n",
    "    print(len(cpt))\n",
    "    print(\"###\")\n",
    "    \n",
    "def print_net_info(net, unrolled = True):\n",
    "    for n in net.get_all_nodes():\n",
    "        print_node_info(net, n)\n",
    "        if not unrolled and net.get_node_id(n) == NodeNames.UPS.value:\n",
    "            plot_time_CPT(net, n)\n",
    "            \n",
    "def calc_stat(confMatrix, outcome, type='P'):\n",
    "    TP = confMatrix[outcome][outcome]\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for i in range(0, len(confMatrix)):\n",
    "        for j in range(0, len(confMatrix[i])):\n",
    "            if i == outcome and j != outcome:\n",
    "                FP += confMatrix[i][j]\n",
    "            if j == outcome and i != outcome:\n",
    "                FN += confMatrix[i][j]\n",
    "            if i != outcome and j != outcome:\n",
    "                TN += confMatrix[i][j] \n",
    "                \n",
    "    if type == 'P':\n",
    "        if TP + FP == 0: return float('nan')\n",
    "        return TP / (TP + FP)\n",
    "    if type == 'A':\n",
    "        if TP + TN + FP + FN == 0: return float('nan')\n",
    "        return  (TP+TN) / (TP + TN + FP + FN)\n",
    "    if type == 'R':\n",
    "        if TP + FN == 0: return float('nan')\n",
    "        return TP / (TP + FN)\n",
    "    if type == 'F':\n",
    "        if (2*TP)+FP+FN == 0: return float('nan')\n",
    "        return (2*TP)/((2*TP)+FP+FN)        \n",
    "\n",
    "def print_validator_results(net, originalSliceCount, validator, nodeId): \n",
    "    nodeHandle = classNodesHandles[nodeId]\n",
    "    outcomeCount = net.get_outcome_count(nodeHandle)\n",
    "    accMtrx = np.zeros((outcomeCount, 2, originalSliceCount))\n",
    "    precMtrx = np.zeros((outcomeCount, 2, originalSliceCount))\n",
    "    recMtrx = np.zeros((outcomeCount, 2, originalSliceCount))\n",
    "    fMtrx = np.zeros((outcomeCount, 2, originalSliceCount))\n",
    "    \n",
    "    \n",
    "    for slice in range(1, originalSliceCount):\n",
    "        if DEBUG: print(\"### Slice \" + str(slice) + \" ###\")\n",
    "        nodeHandle = classNodesHandles[nodeId + \"_\" + str(slice)]\n",
    "        cm = validator.get_confusion_matrix(nodeHandle)\n",
    "        for i in range(0, outcomeCount):\n",
    "            acc = calc_stat(cm, i, 'A')\n",
    "            # If the calculated statistic is NaN assign 0 (see next line)\n",
    "            accMtrx[i][0][slice] = acc if not math.isnan(acc) else 0\n",
    "            # If the calculated statistic is NaN assign weight 0 to it\n",
    "            # otherwise use the number of elements belonging to that class as weight\n",
    "            accMtrx[i][1][slice] = np.sum(cm[:][i]) if not math.isnan(acc) else 0\n",
    "            prec = calc_stat(cm, i, 'P')\n",
    "            precMtrx[i][0][slice] = prec if not math.isnan(prec) else 0\n",
    "            precMtrx[i][1][slice] = np.sum(cm[:][i]) if not math.isnan(prec) else 0\n",
    "            rec = calc_stat(cm, i, 'R')\n",
    "            recMtrx[i][0][slice] = rec if not math.isnan(rec) else 0\n",
    "            recMtrx[i][1][slice] = np.sum(cm[:][i]) if not math.isnan(rec) else 0\n",
    "            f = calc_stat(cm, i, 'F')\n",
    "            fMtrx[i][0][slice] = f if not math.isnan(f) else 0\n",
    "            fMtrx[i][1][slice] = np.sum(cm[:][i]) if not math.isnan(f) else 0\n",
    "            \n",
    "            if DEBUG:\n",
    "                print(\"Accuracy for \" + nodeId + str(i) + \": \" + str(acc))\n",
    "                print(\"Precision for \" + nodeId + str(i) + \": \" + str(prec))\n",
    "                print(\"Recall for \" + nodeId + str(i) + \": \" + str(rec))    \n",
    "        if DEBUG:    \n",
    "            print(\"** Confusion Matrix **\")\n",
    "            for i in range(0, outcomeCount):\n",
    "                print(cm[i])\n",
    "            print(\"\")\n",
    "    \n",
    "    # Calculates weighted averages (each statistic of each timeslice is weighted\n",
    "    # by the number of elements nelonging to that class in that timeslice)\n",
    "    for i in range(0, outcomeCount):\n",
    "        avgAcc = np.sum(accMtrx[i][0]*accMtrx[i][1])/np.sum(accMtrx[i][1])\n",
    "        print(\"Average Accuracy for \" + nodeId + str(i) + \": \" + str(avgAcc))\n",
    "        avgPrec = np.sum(precMtrx[i][0]*precMtrx[i][1])/np.sum(precMtrx[i][1])\n",
    "        print(\"Average Precision for \" + nodeId + str(i) + \": \" + str(avgPrec))\n",
    "        avgRec = np.sum(recMtrx[i][0]*recMtrx[i][1])/np.sum(recMtrx[i][1])\n",
    "        print(\"Average Recall for \" + nodeId + str(i) + \": \" + str(avgRec))\n",
    "        avgF = np.sum(fMtrx[i][0]*fMtrx[i][1])/np.sum(fMtrx[i][1])\n",
    "        print(\"Average F-score for \" + nodeId + str(i) + \": \" + str(avgF))\n",
    "        print(\"\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy for UPS0: 0.8425290523770126\n",
      "Average Precision for UPS0: 0.8676255329981544\n",
      "Average Recall for UPS0: 0.8533190348931866\n",
      "Average F-score for UPS0: 0.8587759093928559\n",
      "\n",
      "Average Accuracy for UPS1: 0.6924509472668035\n",
      "Average Precision for UPS1: 0.6448654519126342\n",
      "Average Recall for UPS1: 0.7280323003867071\n",
      "Average F-score for UPS1: 0.6806446739306031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and read the DBN from file\n",
    "net = pysmile.Network()\n",
    "ds = pysmile.learning.DataSet()\n",
    "\n",
    "net.read_file(os.getcwd() + \"/../../../Genie-DBN/DBN-MITM.xdsl\")\n",
    "df = pd.read_csv(os.getcwd() + \"/outTest.csv\")\n",
    "ds.read_pandas_dataframe(df)\n",
    "   \n",
    "unrolledNet = net.unroll().unrolled     \n",
    "matching = ds.match_network(unrolledNet)\n",
    "validator = pysmile.learning.Validator(unrolledNet, ds, matching)\n",
    "# Set class nodes (those that will not be considered as evidence nodes)\n",
    "for elem in NodeNames.__members__:\n",
    "    if elem not in evidenceNodes:\n",
    "        classNodesHandles[elem] = unrolledNet.get_node(elem)\n",
    "        validator.add_class_node(classNodesHandles[elem])\n",
    "        for slice in range(1, net.get_slice_count()):\n",
    "            elemCat = elem + \"_\" + str(slice)\n",
    "            classNodesHandles[elemCat] = unrolledNet.get_node(elemCat)\n",
    "            validator.add_class_node(classNodesHandles[elemCat])\n",
    "# Test the predctions on the class nodes            \n",
    "validator.test()\n",
    "print_validator_results(unrolledNet, net.get_slice_count(), validator, NodeNames.UPS.value)\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    print_net_info(unrolledNet, unrolled=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On training set\n",
    "\n",
    "Average Accuracy for SRM0: 0.9481999999999999\n",
    "Average Precision for SRM0: 0.8680859303726017\n",
    "Average Recall for SRM0: 0.7572281824391741\n",
    "Average F-score for SRM0: 0.8041382217020009\n",
    "\n",
    "Average Accuracy for SRM1: 0.91892\n",
    "Average Precision for SRM1: 0.6420093076321194\n",
    "Average Recall for SRM1: 0.5619628414066051\n",
    "Average F-score for SRM1: 0.5780565939414026\n",
    "\n",
    "Average Accuracy for SRM2: 0.8892\n",
    "Average Precision for SRM2: 0.6829760288083325\n",
    "Average Recall for SRM2: 0.6042501130623333\n",
    "Average F-score for SRM2: 0.6171060817165118\n",
    "\n",
    "Average Accuracy for SRM3: 0.91856\n",
    "Average Precision for SRM3: 0.8825957866837997\n",
    "Average Recall for SRM3: 0.9481805802708466\n",
    "Average F-score for SRM3: 0.9136529886241248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "def compare_files(trainFileName, testFileName):\n",
    "    dfTrain = pd.read_csv(os.getcwd() + \"/\" + trainFileName)\n",
    "    dfTest = pd.read_csv(os.getcwd() + \"/\" + testFileName)\n",
    "    \n",
    "    dfOut = pd.concat([dfTrain, dfTest]).drop_duplicates(keep=\"first\")\n",
    "    dups  = dfTrain.shape[0] + dfTest.shape[0] - dfOut.shape[0]\n",
    "    print(\"Duplicate rows: \" + str(dups))\n",
    "    \n",
    "compare_files(\"outTrain.csv\", \"outTest.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
