{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "#import pgmpy.models\n",
    "#import pgmpy.inference\n",
    "import numpy as np\n",
    "import pysmile\n",
    "import pysmile_license\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSlices = 24\n",
    "\n",
    "class NodeNames(Enum):\n",
    "    MITM = \"MITM\"\n",
    "    SRM = \"SRM\"\n",
    "    UC = \"UC\"\n",
    "    UPS = \"UPS\"\n",
    "    IMD = \"IMD\"\n",
    "    MC = \"MC\"\n",
    "    CC = \"CC\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySmile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "evidenceNodes = [NodeNames.IMD.value, NodeNames.MC.value, NodeNames.CC.value]\n",
    "\n",
    "trainFileName = \"outTrain2.csv\"\n",
    "testFileName = \"outTest4.csv\"\n",
    "networkFileName = \"DBN-MITM-2States.xdsl\"\n",
    "\n",
    "classNodesHandles = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_node_info(net, node_handle):\n",
    "    print(\"Node id/name: \" + net.get_node_id(node_handle) + \"/\" +\n",
    "    net.get_node_name(node_handle))\n",
    "    print(\" Outcomes: \" + \" \".join(net.get_outcome_ids(node_handle)))\n",
    "    parent_ids = net.get_parent_ids(node_handle)\n",
    "    if len(parent_ids) > 0:\n",
    "        print(\" Parents: \" + \" \".join(parent_ids))\n",
    "    child_ids = net.get_child_ids(node_handle)\n",
    "    if len(child_ids) > 0:\n",
    "        print(\" Children: \" + \" \".join(child_ids))\n",
    "    print_cpt_matrix(net, node_handle)\n",
    "    \n",
    "def print_cpt_matrix(net, node_handle):\n",
    "    cpt = net.get_node_definition(node_handle)\n",
    "    parents = net.get_parents(node_handle)\n",
    "    dim_count = 1 + len(parents)\n",
    "    dim_sizes = [0] * dim_count\n",
    "    for i in range(0, dim_count - 1):\n",
    "        dim_sizes[i] = net.get_outcome_count(parents[i])\n",
    "    dim_sizes[len(dim_sizes) - 1] = net.get_outcome_count(node_handle)\n",
    "    coords = [0] * dim_count\n",
    "    for elem_idx in range(0, len(cpt)):\n",
    "        index_to_coords(elem_idx, dim_sizes, coords)\n",
    "        outcome = net.get_outcome_id(node_handle, coords[dim_count - 1])\n",
    "        out_str = \" P(\" + outcome\n",
    "        if dim_count > 1:\n",
    "            out_str += \" | \"\n",
    "            for parent_idx in range(0, len(parents)):\n",
    "                if parent_idx > 0:\n",
    "                    out_str += \",\"\n",
    "                parent_handle = parents[parent_idx]\n",
    "                out_str += net.get_node_id(parent_handle) + \"=\" + \\\n",
    "                net.get_outcome_id(parent_handle, coords[parent_idx])\n",
    "        prob = cpt[elem_idx]\n",
    "        out_str += \")=\" + str(prob)\n",
    "        print(out_str)\n",
    "    \n",
    "        \n",
    "def index_to_coords(index, dim_sizes, coords):\n",
    "    prod = 1\n",
    "    for i in range(len(dim_sizes) - 1, -1, -1):\n",
    "        coords[i] = int(index / prod) % dim_sizes[i]\n",
    "        prod *= dim_sizes[i]\n",
    "\n",
    "def pint_time_cpt_marix(net, nodeHandle):\n",
    "    timeCPT = net.get_node_temporal_definition(nodeHandle, 1)\n",
    "    \n",
    "        \n",
    "def plot_time_CPT(net, nodeHandle):    \n",
    "    cpt = net.get_node_temporal_definition(nodeHandle, 1)\n",
    "    print(len(cpt))\n",
    "    print(\"###\")\n",
    "    \n",
    "def print_net_info(net, unrolled = True):\n",
    "    for n in net.get_all_nodes():\n",
    "        print_node_info(net, n)\n",
    "        if not unrolled and net.get_node_id(n) == NodeNames.UPS.value:\n",
    "            plot_time_CPT(net, n)\n",
    "            \n",
    "def calc_stat(confMatrix, outcome, type='P'):\n",
    "    TP = confMatrix[outcome][outcome]\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for i in range(0, len(confMatrix)):\n",
    "        for j in range(0, len(confMatrix[i])):\n",
    "            if i == outcome and j != outcome:\n",
    "                FP += confMatrix[i][j]\n",
    "            if j == outcome and i != outcome:\n",
    "                FN += confMatrix[i][j]\n",
    "            if i != outcome and j != outcome:\n",
    "                TN += confMatrix[i][j] \n",
    "                \n",
    "    if type == 'P':\n",
    "        if TP + FP == 0: return float('nan')\n",
    "        return TP / (TP + FP)\n",
    "    if type == 'A':\n",
    "        if TP + TN + FP + FN == 0: return float('nan')\n",
    "        return  (TP+TN) / (TP + TN + FP + FN)\n",
    "    if type == 'R':\n",
    "        if TP + FN == 0: return float('nan')\n",
    "        return TP / (TP + FN)\n",
    "    if type == 'F':\n",
    "        if (2*TP)+FP+FN == 0: return float('nan')\n",
    "        return (2*TP)/((2*TP)+FP+FN)        \n",
    "\n",
    "def print_validator_results(net, originalSliceCount, validator, nodeId): \n",
    "    nodeHandle = classNodesHandles[nodeId]\n",
    "    outcomeCount = net.get_outcome_count(nodeHandle)\n",
    "    accMtrx = np.zeros((outcomeCount, 2, originalSliceCount))\n",
    "    precMtrx = np.zeros((outcomeCount, 2, originalSliceCount))\n",
    "    recMtrx = np.zeros((outcomeCount, 2, originalSliceCount))\n",
    "    fMtrx = np.zeros((outcomeCount, 2, originalSliceCount))\n",
    "    \n",
    "    \n",
    "    for slice in range(1, originalSliceCount):\n",
    "        if DEBUG: print(\"### Slice \" + str(slice) + \" ###\")\n",
    "        nodeHandle = classNodesHandles[nodeId + \"_\" + str(slice)]\n",
    "        cm = validator.get_confusion_matrix(nodeHandle)\n",
    "        for i in range(0, outcomeCount):\n",
    "            acc = calc_stat(cm, i, 'A')\n",
    "            # If the calculated statistic is NaN assign 0 (see next line)\n",
    "            accMtrx[i][0][slice] = acc if not math.isnan(acc) else 0\n",
    "            # If the calculated statistic is NaN assign weight 0 to it\n",
    "            # otherwise use the number of elements belonging to that class as weight\n",
    "            accMtrx[i][1][slice] = np.sum(cm[:][i]) if not math.isnan(acc) else 0\n",
    "            prec = calc_stat(cm, i, 'P')\n",
    "            precMtrx[i][0][slice] = prec if not math.isnan(prec) else 0\n",
    "            precMtrx[i][1][slice] = np.sum(cm[:][i]) if not math.isnan(prec) else 0\n",
    "            rec = calc_stat(cm, i, 'R')\n",
    "            recMtrx[i][0][slice] = rec if not math.isnan(rec) else 0\n",
    "            recMtrx[i][1][slice] = np.sum(cm[:][i]) if not math.isnan(rec) else 0\n",
    "            f = calc_stat(cm, i, 'F')\n",
    "            fMtrx[i][0][slice] = f if not math.isnan(f) else 0\n",
    "            fMtrx[i][1][slice] = np.sum(cm[:][i]) if not math.isnan(f) else 0\n",
    "            \n",
    "            if DEBUG:\n",
    "                print(\"Accuracy for \" + nodeId + str(i) + \": \" + str(acc))\n",
    "                print(\"Precision for \" + nodeId + str(i) + \": \" + str(prec))\n",
    "                print(\"Recall for \" + nodeId + str(i) + \": \" + str(rec))    \n",
    "        if DEBUG:    \n",
    "            print(\"** Confusion Matrix **\")\n",
    "            for i in range(0, outcomeCount):\n",
    "                print(cm[i])\n",
    "            print(\"\")\n",
    "    \n",
    "    # Calculates weighted averages (each statistic of each timeslice is weighted\n",
    "    # by the number of elements nelonging to that class in that timeslice)\n",
    "    avgAccOut = np.zeros(outcomeCount)\n",
    "    avgPrecOut = np.zeros(outcomeCount)\n",
    "    avgRecOut = np.zeros(outcomeCount)\n",
    "    avgFOut = np.zeros(outcomeCount)\n",
    "    for i in range(0, outcomeCount):\n",
    "        avgAccOut[i] = np.sum(accMtrx[i][0]*accMtrx[i][1])/np.sum(accMtrx[i][1])\n",
    "        avgPrecOut[i] = np.sum(precMtrx[i][0]*precMtrx[i][1])/np.sum(precMtrx[i][1])\n",
    "        avgRecOut[i] = np.sum(recMtrx[i][0]*recMtrx[i][1])/np.sum(recMtrx[i][1])\n",
    "        avgFOut[i] = np.sum(fMtrx[i][0]*fMtrx[i][1])/np.sum(fMtrx[i][1])\n",
    "        \n",
    "        \n",
    "        print(\"Average Accuracy for \" + nodeId + str(i) + \": \" + str(avgAccOut[i]))\n",
    "        print(\"Average Precision for \" + nodeId + str(i) + \": \" + str(avgPrecOut[i]))\n",
    "        print(\"Average Recall for \" + nodeId + str(i) + \": \" + str(avgRecOut[i]))\n",
    "        print(\"Average F-score for \" + nodeId + str(i) + \": \" + str(avgFOut[i]))\n",
    "        print(\"\") \n",
    "    \n",
    "    out = {}\n",
    "    out['A'] = np.average(avgAccOut)\n",
    "    out['P'] = np.average(avgPrecOut) \n",
    "    out['R'] = np.average(avgRecOut) \n",
    "    out['F'] = np.average(avgFOut)\n",
    "    return out\n",
    "        \n",
    "            \n",
    "def eraseDefinitions(net):\n",
    "    nodes = net.get_all_node_ids()\n",
    "    for node in nodes:\n",
    "        cpt = net.get_node_definition(node)\n",
    "        numOutcomes = net.get_outcome_count(node)\n",
    "        p = 1 / numOutcomes\n",
    "        for i in range(0, len(cpt)):\n",
    "            cpt[i] = p\n",
    "        net.set_node_definition(node, cpt)\n",
    "\n",
    "def eraseTemporalDefinitions(net):\n",
    "    nodes = net.get_all_node_ids()\n",
    "    for node in nodes:\n",
    "        try:\n",
    "            cpt = net.get_node_temporal_definition(node, 1)\n",
    "            numOutcomes = net.get_outcome_count(node)\n",
    "            p = 1 / numOutcomes\n",
    "            for i in range(0, len(cpt)):\n",
    "                cpt[i] = p\n",
    "            net.set_node_temporal_definition(node, 1, cpt)  \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and read the DBN from file\n",
    "net = pysmile.Network()\n",
    "ds = pysmile.learning.DataSet()\n",
    "\n",
    "net.read_file(os.getcwd() + \"/../../../Genie-DBN/\" + networkFileName)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erase CPTs before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "eraseDefinitions(net)\n",
    "eraseTemporalDefinitions(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traininig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-LL: -183900.29110254004\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.getcwd() + \"/\" + trainFileName)\n",
    "ds.read_pandas_dataframe(df)\n",
    "\n",
    "matching = ds.match_network(net)\n",
    "em = pysmile.learning.EM()\n",
    "# Small data variatons correspond to big changes\n",
    "em.set_relevance(0)\n",
    "res = em.learn(ds, net, matching)\n",
    "\n",
    "print(\"N-LL: \" + str(em.get_last_score()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPerf(net, nodeName, testDs = None):\n",
    "    if testDs is None:\n",
    "        testDs = pd.read_csv(os.getcwd() + \"/\" + testFileName)\n",
    "        \n",
    "    ds.read_pandas_dataframe(testDs)\n",
    "    \n",
    "    unrolledNet = net.unroll().unrolled     \n",
    "    matching = ds.match_network(unrolledNet)\n",
    "    validator = pysmile.learning.Validator(unrolledNet, ds, matching)\n",
    "    # Set class nodes (those that will not be considered as evidence nodes)\n",
    "    for elem in NodeNames.__members__:\n",
    "        if elem not in evidenceNodes:\n",
    "            classNodesHandles[elem] = unrolledNet.get_node(elem)\n",
    "            validator.add_class_node(classNodesHandles[elem])\n",
    "            for slice in range(1, net.get_slice_count()):\n",
    "                elemCat = elem + \"_\" + str(slice)\n",
    "                classNodesHandles[elemCat] = unrolledNet.get_node(elemCat)\n",
    "                validator.add_class_node(classNodesHandles[elemCat])\n",
    "    # Test the predctions on the class nodes            \n",
    "    validator.test()\n",
    "    if DEBUG:\n",
    "        print_net_info(unrolledNet, unrolled=True)\n",
    "    \n",
    "    return print_validator_results(unrolledNet, net.get_slice_count(), validator, nodeName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "4000\n",
      "Duplicate rows: 4003\n"
     ]
    }
   ],
   "source": [
    "def compare_files(trainFileName, testFileName):\n",
    "    dfTrain = pd.read_csv(os.getcwd() + \"/\" + trainFileName)\n",
    "    dfTest = pd.read_csv(os.getcwd() + \"/\" + testFileName)\n",
    "    \n",
    "    dfOut = pd.concat([dfTrain, dfTest]).drop_duplicates(keep=\"first\")\n",
    "    dups  = dfTrain.shape[0] + dfTest.shape[0] - dfOut.shape[0]\n",
    "    print(dfTrain.shape[0])\n",
    "    print(dfTest.shape[0])\n",
    "    print(\"Duplicate rows: \" + str(dups))\n",
    "    \n",
    "compare_files(\"outTrain4.csv\", \"outTrain4.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test learning capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-LL: -147820.84904475397\n",
      "Average Accuracy for UPS0: 0.8432276293304334\n",
      "Average Precision for UPS0: 0.8597949355289731\n",
      "Average Recall for UPS0: 0.8637586867149311\n",
      "Average F-score for UPS0: 0.8599780349443845\n",
      "\n",
      "Average Accuracy for UPS1: 0.7003299873537779\n",
      "Average Precision for UPS1: 0.666613974075245\n",
      "Average Recall for UPS1: 0.7265923599072064\n",
      "Average F-score for UPS1: 0.6917333654475485\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dosclic98/Desktop/Materiale_Uni/Magistrale/Tesi_Magistrale/MMS/TX_Medium_Exp/simulations/analysis/learnerDBN.ipynb Cella 15\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dosclic98/Desktop/Materiale_Uni/Magistrale/Tesi_Magistrale/MMS/TX_Medium_Exp/simulations/analysis/learnerDBN.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m eraseDefinitions(net)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dosclic98/Desktop/Materiale_Uni/Magistrale/Tesi_Magistrale/MMS/TX_Medium_Exp/simulations/analysis/learnerDBN.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m eraseTemporalDefinitions(net)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dosclic98/Desktop/Materiale_Uni/Magistrale/Tesi_Magistrale/MMS/TX_Medium_Exp/simulations/analysis/learnerDBN.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m res \u001b[39m=\u001b[39m em\u001b[39m.\u001b[39;49mlearn(ds, net, matching)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dosclic98/Desktop/Materiale_Uni/Magistrale/Tesi_Magistrale/MMS/TX_Medium_Exp/simulations/analysis/learnerDBN.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m em\u001b[39m.\u001b[39mset_randomize_parameters(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dosclic98/Desktop/Materiale_Uni/Magistrale/Tesi_Magistrale/MMS/TX_Medium_Exp/simulations/analysis/learnerDBN.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m nlls\u001b[39m.\u001b[39mappend(em\u001b[39m.\u001b[39mget_last_score())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "popSize = 4500\n",
    "nlls = []\n",
    "accs = []\n",
    "precs = []\n",
    "recs = []\n",
    "fs = []\n",
    "df = pd.read_csv(os.getcwd() + \"/\" + trainFileName)\n",
    "kfold = KFold(n_splits=5)\n",
    "for trainDs, testDs in kfold.split(df[0:popSize]):\n",
    "    ds.read_pandas_dataframe(df.iloc[trainDs])\n",
    "    matching = ds.match_network(net)\n",
    "    em = pysmile.learning.EM()\n",
    "    # Small data variatons correspond to big changes\n",
    "    em.set_relevance(0)\n",
    "    eraseDefinitions(net)\n",
    "    eraseTemporalDefinitions(net)\n",
    "    res = em.learn(ds, net, matching)\n",
    "    em.set_randomize_parameters(True)\n",
    "    nlls.append(em.get_last_score())\n",
    "    print(\"N-LL: \" + str(em.get_last_score()))\n",
    "    \n",
    "    nodeName = NodeNames.UPS.value\n",
    "    out = testPerf(net, nodeName, testDs = df.iloc[testDs])\n",
    "    accs.append(out['A'])\n",
    "    precs.append(out['P'])\n",
    "    recs.append(out['R'])\n",
    "    fs.append(out['F'])\n",
    "\n",
    "print(\"Average Accuracy on node \" + nodeName + \": \" + str(np.average(accs)))\n",
    "print(\"Average Precision on node \" + nodeName + \": \" + str(np.average(precs)))\n",
    "print(\"Average Recall on node \" + nodeName + \": \" + str(np.average(recs)))\n",
    "print(\"Average F-score on node \" + nodeName + \": \" + str(np.average(fs)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
